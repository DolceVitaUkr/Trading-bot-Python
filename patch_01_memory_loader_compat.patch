--- a/tradingbot/core/persistence.py
+++ b/tradingbot/core/persistence.py
@@ -0,0 +1,48 @@
+import json, os, tempfile, time, shutil
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+def atomic_write_json(path: Path, data: Any) -> None:
+    path = Path(path)
+    tmp = path.with_suffix(path.suffix + ".tmp")
+    with open(tmp, "w", encoding="utf-8") as f:
+        json.dump(data, f, indent=2, default=str)
+    os.replace(tmp, path)
+
+def safe_read_json(path: Path, default: Any=None) -> Any:
+    path = Path(path)
+    if not path.exists():
+        return default
+    with open(path, "r", encoding="utf-8") as f:
+        return json.load(f)
+
+def snapshot_file(path: Path, snapshot_dir: Path, keep: int = 30) -> Optional[Path]:
+    path = Path(path); snapshot_dir = Path(snapshot_dir)
+    if not path.exists(): return None
+    snapshot_dir.mkdir(parents=True, exist_ok=True)
+    ts = time.strftime("%Y%m%d-%H%M%S")
+    snap_path = snapshot_dir / f"{path.name}.{ts}.snap"
+    shutil.copy2(path, snap_path)
+    # trim old
+    snaps = sorted(snapshot_dir.glob(f"{path.name}.*.snap"))
+    for old in snaps[:-keep]:
+        try: old.unlink()
+        except: pass
+    return snap_path
+
+class WriteAheadLog:
+    def __init__(self, wal_path: Path):
+        self.wal_path = Path(wal_path)
+        self.wal_path.parent.mkdir(parents=True, exist_ok=True)
+        if not self.wal_path.exists():
+            with open(self.wal_path, "w", encoding="utf-8") as f:
+                pass
+
+    def append(self, record: Dict[str, Any]) -> None:
+        with open(self.wal_path, "a", encoding="utf-8") as f:
+            f.write(json.dumps(record, default=str) + "\n")
+
+    def read_all(self):
+        if not self.wal_path.exists(): return []
+        with open(self.wal_path, "r", encoding="utf-8") as f:
+            return [json.loads(line) for line in f if line.strip()]--- a/tradingbot/core/reconciler.py
+++ b/tradingbot/core/reconciler.py
@@ -0,0 +1,23 @@
+from typing import Callable, Optional, List, Dict, Any
+from pathlib import Path
+from .persistence import safe_read_json, atomic_write_json
+from .loggerconfig import get_logger
+
+log = get_logger(__name__)
+
+class Reconciler:
+    def __init__(self, state_path: Path, fetch_broker_orders: Optional[Callable[[], List[Dict[str, Any]]]] = None):
+        self.state_path = Path(state_path)
+        self.fetch_broker_orders = fetch_broker_orders
+
+    async def reconcile(self) -> None:
+        try:
+            local = safe_read_json(self.state_path, default={})
+            if not self.fetch_broker_orders:
+                log.info("Reconciler: no broker fetcher supplied; skipping")
+                return
+            remote_orders = await self.fetch_broker_orders()
+            # TODO: implement robust merge rules. For now, just log size.
+            log.info(f"Reconciler: fetched {len(remote_orders)} broker orders for reconciliation")
+        except Exception as e:
+            log.error(f"Reconciler failed: {e}")--- a/tradingbot/core/strategy_development_manager.py
+++ b/tradingbot/core/strategy_development_manager.py
@@ -92,7 +92,16 @@
                     data = json.load(f)
                     for strategy_id, strategy_data in data.items():
                         # Convert status string back to enum
-                        strategy_data['status'] = StrategyStatus(strategy_data['status'])
+                        # Normalize legacy statuses before casting
+legacy_map = {
+    "running": "developing",
+    "active": "developing",
+    "enabled": "developing",
+    "online": "developing"
+}
+raw_status = strategy_data.get('status', 'developing')
+raw_status = legacy_map.get(raw_status, raw_status)
+strategy_data['status'] = StrategyStatus(raw_status)
                         # Reconstruct dataclasses
                         metrics_data = strategy_data['metrics']
                         metrics = StrategyMetrics(**metrics_data)
